---
layout: single
title: "Map... twitter data using rtweet"
excerpt: "This lesson provides an example of modularizing code in R. "
authors: ['Carson Farmer', 'Leah Wasser']
modified: '`r format(Sys.time(), "%Y-%m-%d")`'
category: [course-materials]
class-lesson: ['social-media-r']
permalink: /course-materials/earth-analytics/week-12/map-twitter-data-r/
nav-title: 'Mapping twitter data'
week: 12
sidebar:
  nav:
author_profile: false
comments: true
order: 3
lang-lib:
  r: ['rtweet']
tags2:
  social-science: ['social-media']
---

{% include toc title="In This Lesson" icon="file-text" %}

<div class='notice--success' markdown="1">

## <i class="fa fa-graduation-cap" aria-hidden="true"></i> Learning Objectives

After completing this tutorial, you will be able to:

*

## <i class="fa fa-check-square-o fa-2" aria-hidden="true"></i> What you need

You will need a computer with internet access to complete this lesson.

</div>
## Geographic searches
- How about all recent tweets around Boulder (within 10 miles)?

```{r}
# About the center of Boulder... give or take
geocode <- '40.0150,-105.2705,50mi'
boulder_tweets <- search_tweets("", n=1000, lang="en",
                       geocode=geocode)
head(boulder_tweets)
```

Where are they from around CO?

```{r}
boulder_users <- attributes(boulder_tweets)$users
boulder_users$location

```

What type of following do they have?
```{r}

boulder_users$followers_count
summary(boulder_users$followers_count)
max_val <- max(boulder_users$followers_count)

# looks like there is an outlier -- let's use breaks to make this easier to look at
ggplot(boulder_users, aes(followers_count)) +
         geom_histogram(breaks=c(0,100,1000,10000,100000, 200000,max_val))

```



Basic Mapping and Analysis
========================================================
title: false

<center>
```{r echo=FALSE, fig.height=10, fig.width=10}
m + pres_theme
```
</center>

Adding Some Context...
========================================================

- Plotting on Stamen Terrain basemap provides useful context...

```{r eval=FALSE, fig.show='hide', message=FALSE, warning=FALSE}
# Create Boulder basemap (geocoding by name)
# NOTE: This doesn't work right now...
Boulder = get_map(location="Boulder, CO, USA",
                  source="stamen", maptype="terrain",
                  crop=FALSE, zoom=10)
# Create base ggmap
ggmap(Boulder) +
  # Start adding elements...
  geom_point(data=xy, aes(x, y), color="red",
             size=5, alpha=0.5) +
  stat_density2d(data=xy, aes(x, y, fill=..level..,
                              alpha=..level..),
                 size=0.01, bins=16, geom='polygon')
```

Twitter with Context
========================================================
title: false
<center>
```{r eval=FALSE, echo=FALSE, fig.height=10, fig.width=10, message=FALSE, warning=FALSE}
ggmap(Boulder) +
  geom_point(data=xy, aes(x, y), color="red", size=2, alpha=0.5) +
  stat_density2d(data=xy, aes(x, y,  fill=..level.., alpha=..level..),
                              size=0.01, bins=16, geom='polygon') +
  pres_theme
```
</center>

Computing 'Clusters'
========================================================

- Or we can compute clusters 'on the fly', again using the powerful `leaflet` package:

```{r cache=FALSE}
# URL for 'custom' icon
url = "http://steppingstonellc.com/wp-content/uploads/twitter-icon-620x626.png"
twitter = makeIcon(url, url, 32, 31)  # Create Icon!

# How about auto-clustering?!
map = leaflet(xy) %>%
  addProviderTiles("Stamen.Terrain") %>%
  addMarkers(lng=~x, lat=~y, popup=~text,
    clusterOptions=markerClusterOptions(),
    icon=twitter)
```
```{r echo=FALSE, eval=FALSE}
saveWidget(widget=map, file="twitter_map.html", selfcontained=TRUE)
```

Interactive Map of Twitter Data
========================================================
title: false


Going a Step Further
========================================================
type: section

It isn't really enough just to grab some web-data and start mapping. Afterall, this session is really about data integration---something web-data and APIs are particularly good for!

Heat Maps are NOT Enough...
========================================================

<center>
[![xkcd Heat Maps](http://imgs.xkcd.com/comics/heatmap.png)](http://xkcd.com/1138/)
</center>

Combining Tweets and Census Info
========================================================

- Let's take another look at our Census data (this time grabbing population counts for Boulder region)
```{r}
pop = acs.fetch(endyear=2014, span=5, geography=geo,
                table.number="B01003",
                col.names="pretty")
est = pop@estimate  # Grab the Total Population
# Create a new data.frame
pop = data.frame(geoid, est[, 1],
                 stringsAsFactors=FALSE)
rownames(pop) = 1:nrow(inc)  # Rename rows
colnames(pop) = c("GEOID", "pop_total")  # Rename columns
```
- Create the merged data.frame!
```{r}
merged = geo_join(tracts, pop, "GEOID", "GEOID")
```

Big Ol' Chunk of Leaflet Code
========================================================

```{r cache=FALSE}
popup = paste0("GEOID: ", merged$GEOID,
               "<br/>Total Population: ",
               round(merged$pop_total, 2))
pal = colorNumeric(palette="YlGnBu",
                   domain=merged$pop_total)
map = leaflet() %>%  # Map time!
  addProviderTiles("CartoDB.Positron") %>%
  addPolygons(data=merged, popup=popup,
              fillColor=~pal(pop_total),
              color="#b2aeae", # This is a 'hex' color
              fillOpacity=0.7, weight=1,
              smoothFactor=0.2) %>%
  addCircles(data=xy, lng=~x, lat=~y,
             popup=~text, radius=5) %>%
  addLegend(pal=pal, values=merged$pop_total,
            position="bottomright",
            title="Total Population")
```

```{r echo=FALSE, eval=FALSE}
saveWidget(widget=map, file="dual_map.html", selfcontained=TRUE)
```

Interactive Map of Twitter Data
========================================================
title: false


Controlling for Population
========================================================

- That's all fine and good, but are areas with lots of tweets associated with areas of high population? Its hard to tell from the map...
```{r}
library(sp)
# Make the points a SpatialPointsDataFrame
coordinates(xy) = ~x+y
proj4string(xy) = CRS("+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0")
# Put the x/y data back into the data slot for later...
xy@data = as.data.frame(xy)
```
- And now we count 'points in polygon':
```{r}
overlay = over(xy, merged)
res = as.data.frame(table(overlay$GEOID))
colnames(res) = c("GEOID", "count")
```

Tweet Score?
========================================================

- We can then join counts back onto the counties:
```{r}
merged@data = join(merged@data, res, by="GEOID")
# And compute a 'tweet score'... based on logged pop
merged$percapita = merged$count/log(merged$pop_total)
```
- Based on this new variable, we setup a new pallette:
```{r}
pal = colorNumeric(palette="YlGnBu",
                   domain=merged$percapita)
# Also create a nice popup for display...
popup = paste0("GEOID: ", merged$GEOID, "<br>",
               "Score: ", round(merged$percapita, 2))
```
- And we plot it!

Plotting the Tweets
========================================================
title: false

```{r cache=FALSE, echo=FALSE, eval=FALSE}
map = leaflet() %>%
  addProviderTiles("CartoDB.Positron", group="Base") %>%
  addPolygons(data=merged, popup=popup,
              fillColor=~pal(percapita),
              color="#b2aeae", # This is a 'hex' color
              fillOpacity=0.7, weight=1,
              smoothFactor=0.2, group="Score") %>%
  addCircleMarkers(data=xy, lng=~x, lat=~y, radius=4,
                   stroke=FALSE, popup=~text, group="Tweets") %>%
  addLayersControl(overlayGroups=c("Tweets", "Score"),
                   options=layersControlOptions(collapsed=FALSE)) %>%
  addLegend(pal=pal, values=merged$percapita,
            position="bottomright",
            title="Score")

saveWidget(widget=map, file="final_map.html", selfcontained=TRUE)
```



Wanna See the Code for That One?
========================================================

```{r eval=FALSE}
leaflet() %>%
  addProviderTiles("CartoDB.Positron", group="Base") %>%
  addPolygons(data=merged, popup=popup,
              fillColor=~pal(percapita),
              color="#b2aeae", # This is a 'hex' color
              fillOpacity=0.7, weight=1,
              smoothFactor=0.2, group="Score") %>%
  addCircleMarkers(data=xy, lng=~x, lat=~y, radius=4,
                   stroke=FALSE, popup=~text,
                   group="Tweets") %>%
  addLayersControl(overlayGroups=c("Tweets", "Score"),
                   options=layersControlOptions(
                     collapsed=FALSE)) %>%
  addLegend(pal=pal, values=merged$percapita,
            position="bottomright",
            title="Score")
```

That's All Folks!
========================================================
type: section

## Data Harmonization + Working with Web and Social Media Data
Earth Analytics---Spring 2016

Carson J. Q. Farmer
[carson.farmer@colorado.edu]()

babs buttenfield
[babs@colorado.edu]()

References
========================================================
type: sub-section

- Most of the content in this tutorial was 'borrowed' from one of the following sources:
    - [Leaflet for `R`](https://rstudio.github.io/leaflet/)
    - [An Introduction to `R` for Spatial Analysis & Mapping](https://us.sagepub.com/en-us/nam/an-introduction-to-r-for-spatial-analysis-and-mapping/book241031)
    - [Manipulating and mapping US Census data in `R`](http://zevross.com/blog/2015/10/14/manipulating-and-mapping-us-census-data-in-r-using-the-acs-tigris-and-leaflet-packages-3/#census-data-the-hard-way)
- Data was courtesy of:
    - [Colorado Information Marketplace](https://data.colorado.gov)
    - [Twitter's API](https://dev.twitter.com/rest/public)
    - [US Census ACS 5-Year Data API](https://www.census.gov/data/developers/data-sets/acs-survey-5-year-data.html)

Want to Play Some More?
========================================================

- Check out the [EnviroCar API](http://envirocar.github.io/enviroCar-server/api/)
    - Data on vehicle trajectories annotated with CO^2 emmisions!
- [PHL API](http://phlapi.com)---Open Data for the City of Philly
- [NYC Open Data Portal](https://nycopendata.socrata.com)---Open Data for NYC
- [SF OpenData](https://data.sfgov.org)---Open Data for San Fran
- ... you get the point!

- In general, the [Programmable Web](http://www.programmableweb.com/) is a good resource
    - Here are [146 location APIs](http://www.programmableweb.com/news/146-location-apis-foursquare-panoramio-and-geocoder/2012/06/20) for example...
